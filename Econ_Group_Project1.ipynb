{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mConnection is disposed. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from statsmodels.stats.diagnostic import het_breuschpagan, acorr_breusch_godfrey\n",
    "from statsmodels.stats.stattools  import durbin_watson\n",
    "from scipy.stats import shapiro, normaltest, probplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset with new features\n",
    "df = pd.read_excel('Project1Data.xlsx')\n",
    "\n",
    "# Create the log of variables for better modeling (log-log model for elasticities)\n",
    "df['log_qu'] = np.log(df['qu'])\n",
    "df['log_cprice'] = np.log(df['cprice'])\n",
    "df['log_tprice'] = np.log(df['tprice'])\n",
    "df['log_oprice'] = np.log(df['oprice'])\n",
    "df['log_income'] = np.log(df['incom'])\n",
    "df['log_wprice'] = np.log(df['wprice'])\n",
    "df['log_bprice'] = np.log(df['bprice'])\n",
    "df['log_woodpulp'] = np.log(df['woodpulp'])\n",
    "df['log_BrazilPrecipitation'] = np.log(df['BrazilPrecipitation'])\n",
    "df['log_BrazilTASMean'] = np.log(df['BrazilTAS_Mean'])\n",
    "df['log_BrazilTASMax'] = np.log(df['BrazilTAS_Max'])\n",
    "df['log_EthioPrecipitation'] = np.log(df['EthioPrecipitation'])\n",
    "df['log_ColombPrecipitation'] = np.log(df['ColombPrecipitation'])\n",
    "df['log_VietPrecipitation'] = np.log(df['VietPrecipitation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ds_ols(df, x_cols, y_col, const=True, print_summary=True, plot_name=''):\n",
    "    '''\n",
    "    demand / supply function\n",
    "    df : input data (dataframe)\n",
    "    x_cols : X variables\n",
    "    y_col : Y variable\n",
    "    '''\n",
    "    # OLS \n",
    "    X = df[x_cols]\n",
    "    y = df[y_col]\n",
    "\n",
    "    # add a constant to the independent variable (intercept)\n",
    "    if const:\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "    # fit the regression model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "\n",
    "    # output the summary of the regression\n",
    "    model_summary = model.summary()\n",
    "    # print('model_summary:')\n",
    "    # print(model_summary)\n",
    "    if print_summary:\n",
    "        print(plot_name,':')\n",
    "        print(model_summary)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>OLS with log transformed variables</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demand function estimate\n",
    "demand_ols = ds_ols(df, x_cols=['log_cprice','log_income','q1','q2','q3'], y_col=['log_qu'], plot_name='Demand function summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supply function estimate\n",
    "X_supply = ['log_cprice','log_wprice','q1','q2','q3']\n",
    "y_supply = ['log_qu']\n",
    "supply_ols = ds_ols(df, x_cols=['log_cprice','log_wprice','q1','q2','q3'], y_col=y_supply, plot_name='Supply function summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TSLS with log transformed variables</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand TSLS\n",
    "demand_first_stage = ds_ols(df, x_cols=['log_bprice', 'log_wprice', 'log_income', 'q1', 'q2', 'q3'], y_col=['log_cprice'], plot_name='demand first stage')\n",
    "df['log_cprice_pred_demand'] = demand_first_stage.fittedvalues\n",
    "demand_second_stage = ds_ols(df, x_cols=['log_cprice_pred_demand','log_income','q1','q2','q3'], y_col=['log_qu'], plot_name='demand second stage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supply TSLS\n",
    "supply_first_stage = ds_ols(df, x_cols=['log_wprice', 'log_income', 'q1', 'q2', 'q3'], y_col=['log_cprice'], plot_name='supply first stage')\n",
    "df['log_cprice_pred_supply'] = supply_first_stage.fittedvalues\n",
    "supply_second_stage = ds_ols(df, x_cols=['log_cprice_pred_supply','log_wprice','q1','q2','q3'], y_col=['log_qu'], plot_name='supply second stage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Hausman Test</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the test statistic (Demand)\n",
    "\n",
    "beta_demand_ols = demand_ols.params['log_cprice']\n",
    "beta_demand_iv = demand_second_stage.params['log_cprice_pred_demand']\n",
    "\n",
    "var_beta_demand_ols = demand_ols.cov_params().loc['log_cprice','log_cprice']\n",
    "var_beta_demand_iv = demand_second_stage.cov_params().loc['log_cprice_pred_demand','log_cprice_pred_demand']\n",
    "\n",
    "# Test statistic\n",
    "H_demand = (beta_demand_ols - beta_demand_iv)**2 / (var_beta_demand_iv - var_beta_demand_ols)\n",
    "\n",
    "# p-value\n",
    "from scipy.stats.distributions import chi2\n",
    "print(f'p-value : {chi2.sf(H_demand,1)}') # Degrees of freedom = numbers of parameters tested (usually the number of endogenous regressors)\n",
    "print('')\n",
    "#### betas and their var (Demand)\n",
    "print(f'beta_demand_iv : {beta_demand_iv}')\n",
    "print(f'beta_demand_ols : {beta_demand_ols}')\n",
    "print(f'var_beta_demand_ols : {var_beta_demand_ols}')\n",
    "print(f'var_beta_demand_iv : {var_beta_demand_iv}')\n",
    "print(f'H_demand : {H_demand}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the test statistic (Supply)\n",
    "\n",
    "beta_supply_ols = supply_ols.params['log_cprice']\n",
    "beta_supply_iv = supply_second_stage.params['log_cprice_pred_supply'] # beta from 2SLS\n",
    "\n",
    "var_beta_supply_ols = supply_ols.cov_params().loc['log_cprice','log_cprice']\n",
    "var_beta_supply_iv = supply_second_stage.cov_params().loc['log_cprice_pred_supply','log_cprice_pred_supply']\n",
    "\n",
    "# Test statistic\n",
    "H_supply = (beta_supply_ols - beta_supply_iv)**2 / (var_beta_supply_iv - var_beta_supply_ols)\n",
    "\n",
    "# p-value\n",
    "print(f'p-value: {chi2.sf(H_supply,1)}') # Degrees of freedom = numbers of parameters tested (usually the number of endogenous regressors)'\n",
    "print('')\n",
    "#### betas and their var (Supply)\n",
    "print(f'beta_supply_ols : {beta_supply_ols}')\n",
    "print(f'beta_supply_iv : {beta_supply_iv}')\n",
    "print(f'var_beta_supply_ols : {var_beta_supply_ols}')\n",
    "print(f'var_beta_supply_iv : {var_beta_supply_iv}')\n",
    "print(f'H_supply : {H_supply}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Multiple Linear Regression Assumptions</h1>\n",
    "<ul>\n",
    "<li>Linearity</li>\n",
    "<li>Independence</li>\n",
    "<li>Homoskedacity</li>\n",
    "<li>Normality</li>\n",
    "<li>Independent variables are not highly correlated</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings # ignore warning\n",
    "\n",
    "# 1. Linearity: Residuals vs Fitted Plot\n",
    "def plot_linearity(X, y):\n",
    "    n_features = X.shape[1]-1\n",
    "    n_features_to_plot = n_features - 3  # Exclude the last 3 dummy variable plots\n",
    "    \n",
    "    fig, axes = plt.subplots(n_features_to_plot, 1, figsize=(8, n_features_to_plot * 4))\n",
    "\n",
    "    for i, col in enumerate(X.columns[1:n_features_to_plot+1]):  # Skip the constant term\n",
    "        # Define the independent variable (X) and dependent variable (Y)\n",
    "        X_lin = df[col] \n",
    "        y_lin = y\n",
    "        # Add a constant to the independent variable (intercept)\n",
    "        X_lin = sm.add_constant(X_lin)\n",
    "        # Fit the regression model\n",
    "        model_lin = sm.OLS(y_lin, X_lin).fit()\n",
    "\n",
    "        fitted_values_lin = model_lin.fittedvalues\n",
    "\n",
    "        sns.scatterplot(x=X[col], y=y, ax=axes[i])\n",
    "        sns.lineplot(x=X[col], y=fitted_values_lin, ax=axes[i], color='red')\n",
    "        # sns.lineplot(x=X[col], y=y, color='red', ax=axes[i], ci=None)\n",
    "        axes[i].set_title(f'{col} vs log_qu (Linearity Check: : Scatter Plot with Regression Line)')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('log_qu')\n",
    "\n",
    "        # Set the y-axis scale (zoom out)\n",
    "        ymin, ymax = axes[i].get_ylim()  # Get current y-axis limits\n",
    "        axes[i].set_ylim(ymin * 2, ymax * 2)  # Scale the y-axis\n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()  \n",
    "      \n",
    "# 2. Independence: Durbin-Watson Test\n",
    "def check_independence(model):\n",
    "    residuals = model.resid\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(residuals, marker='o', linestyle='none', color='blue')\n",
    "    plt.axhline(y=0, color='red', linestyle='--')\n",
    "    plt.title('Residuals vs Observation Index (Independence Check)')\n",
    "    plt.xlabel('Observation Index')\n",
    "    plt.ylabel('Residuals')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# 3. Homoscedasticity: Residuals Plot\n",
    "def check_homoscedasticity(model, X):\n",
    "    residuals = model.resid\n",
    "    \n",
    "    # Subplots of Residuals against each independent variable\n",
    "    n_features = X.shape[1]-1 # Exclude the constant term\n",
    "    n_features_to_plot = n_features - 3  # Exclude the last 3 dummy variable plots\n",
    "    \n",
    "    fig, axes = plt.subplots(n_features_to_plot, 1, figsize=(8, n_features_to_plot * 4))\n",
    "\n",
    "    for i, col in enumerate(X.columns[1:n_features_to_plot+1]):  # Skip the constant term\n",
    "        sns.residplot(x=X[col], y=residuals, lowess=True, line_kws={'color': 'red', 'lw': 2}, ax=axes[i])\n",
    "        axes[i].set_title(f'Residuals vs {col}')\n",
    "        axes[i].set_xlabel(col)\n",
    "        axes[i].set_ylabel('Residuals')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 4. Normality\n",
    "def check_normality(model):\n",
    "    residuals = model.resid\n",
    "\n",
    "    # Histogram of residuals\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(residuals, bins=30, kde=True)\n",
    "    plt.title('Histogram of Residuals (Normality Check)')\n",
    "    plt.xlabel('Residuals')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Running all assumption checks\n",
    "def check_assumptions(model, X, y):\n",
    "    print(\"Checking Linearity...\")\n",
    "    plot_linearity(X, y)\n",
    "    \n",
    "    print(\"\\nChecking Independence...\")\n",
    "    check_independence(model)\n",
    "    \n",
    "    print(\"\\nChecking Homoskedasticity...\")\n",
    "    check_homoscedasticity(model, X)\n",
    "    \n",
    "    print(\"\\nChecking Normality...\")\n",
    "    check_normality(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_demand_tsls = df[['log_cprice_pred_demand','log_income','q1','q2','q3']]\n",
    "X_demand_tsls = sm.add_constant(X_demand_tsls)\n",
    "y_demand_tsls = df['log_qu']\n",
    "\n",
    "check_assumptions(demand_second_stage, X_demand_tsls, y_demand_tsls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Typically, a correlation coefficient above 0.8 or 0.9 between two independent variables suggests multicollinearity may exist.\n",
    "\n",
    "Source: https://sougaaat.medium.com/multicollinearity-explained-dealing-with-correlated-variables-in-regression-analysis-a76e215fb13c#:~:text=If%20there%20are%20off%2Ddiagonal,and%20may%20be%20causing%20multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Assumption: Independent variables are not highly correlated\n",
    "\n",
    "# Create a correlation matrix\n",
    "corr_matrix = X_demand.corr()\n",
    "\n",
    "# Plot a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variance Inflation Factor (VIF)\n",
    "\n",
    "A variance inflation factor (VIF) is a measure of the amount of multicollinearity in regression analysis. Multicollinearity exists when there is a correlation between multiple independent variables in a multiple regression model.\n",
    "\n",
    "In general terms,\n",
    "\n",
    "<li>VIF equal to 1 = variables are not correlated</li>\n",
    "<li>VIF between 1 and 5 = variables are moderately correlated</li>\n",
    "<li>VIF greater than 5 = variables are highly correlated</li>\n",
    "\n",
    "Source: https://www.investopedia.com/terms/v/variance-inflation-factor.asp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Assumption: Independent variables are not highly correlated\n",
    "\n",
    "# Variance Inflation Factor (VIF)\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "X_demand_with_const = sm.add_constant(X_demand_tsls)\n",
    "\n",
    "# Compute VIF for each feature\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = X_demand.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X_demand.values, i) for i in range(X_demand.shape[1])]\n",
    "\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_supply_tsls = df[['log_cprice_pred_supply','log_wprice','q1','q2','q3']]\n",
    "X_supply_tsls = sm.add_constant(X_supply_tsls)\n",
    "y_supply_tsls = df['log_qu']\n",
    "\n",
    "check_assumptions(supply_second_stage, X_supply_tsls, y_supply_tsls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Assumption: Independent variables are not highly correlated\n",
    "\n",
    "# Create a correlation matrix\n",
    "corr_matrix = X_supply.corr()\n",
    "\n",
    "# Plot a heatmap of the correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Assumption: Independent variables are not highly correlated\n",
    "\n",
    "# Variance Inflation Factor (VIF)\n",
    "\n",
    "# Compute VIF for each feature\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = X_supply.columns\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X_supply.values, i) for i in range(X_supply.shape[1])]\n",
    "\n",
    "print(vif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Trying other Models</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train and evaluate models\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    return mse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Dd (Demand) Model Features ---\n",
    "X_demand = df[['cprice', 'tprice', 'oprice', 'incom', 'q1', 'q2', 'q3', 'q4']]  # Demand side features\n",
    "y_demand = df['qu']  # Target variable (quantity)\n",
    "\n",
    "# --- Ss (Supply) Model Features ---\n",
    "X_supply = df[['cprice', 'bprice', 'wprice', 'q1', 'q2', 'q3', 'q4']]  # Supply side features\n",
    "y_supply = df['qu']  # Target variable (quantity)\n",
    "\n",
    "# Train-Test Split\n",
    "X_demand_train, X_demand_test, y_demand_train, y_demand_test = train_test_split(X_demand, y_demand, test_size=0.2, random_state=42)\n",
    "X_supply_train, X_supply_test, y_supply_train, y_supply_test = train_test_split(X_supply, y_supply, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data (for Ridge, Lasso, SVR)\n",
    "scaler_demand = StandardScaler()\n",
    "X_demand_train_scaled = scaler_demand.fit_transform(X_demand_train)\n",
    "X_demand_test_scaled = scaler_demand.transform(X_demand_test)\n",
    "\n",
    "scaler_supply = StandardScaler()\n",
    "X_supply_train_scaled = scaler_supply.fit_transform(X_supply_train)\n",
    "X_supply_test_scaled = scaler_supply.transform(X_supply_test)\n",
    "\n",
    "# Define models for comparison (can add more models)\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(),\n",
    "    \"Lasso Regression\": Lasso(),\n",
    "    \"Decision Tree\": DecisionTreeRegressor(),\n",
    "    \"Random Forest\": RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# Try models for Dd (Demand) and Ss (Supply)\n",
    "results_demand = {}\n",
    "results_supply = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} for Demand model (Dd)...\")\n",
    "    mse_d, r2_d = evaluate_model(model, X_demand_train_scaled, y_demand_train, X_demand_test_scaled, y_demand_test)\n",
    "    results_demand[name] = {\"MSE\": mse_d, \"R^2\": r2_d}\n",
    "\n",
    "    print(f\"Training {name} for Supply model (Ss)...\")\n",
    "    mse_s, r2_s = evaluate_model(model, X_supply_train_scaled, y_supply_train, X_supply_test_scaled, y_supply_test)\n",
    "    results_supply[name] = {\"MSE\": mse_s, \"R^2\": r2_s}\n",
    "\n",
    "# Convert results to DataFrames for easy comparison\n",
    "results_demand_df = pd.DataFrame(results_demand).T\n",
    "results_supply_df = pd.DataFrame(results_supply).T\n",
    "\n",
    "# Display the results for Demand (Dd) and Supply (Ss)\n",
    "print(\"\\nDemand (Dd) Model Performance:\")\n",
    "print(results_demand_df.sort_values(by='R^2', ascending=False))\n",
    "\n",
    "print(\"\\nSupply (Ss) Model Performance:\")\n",
    "print(results_supply_df.sort_values(by='R^2', ascending=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Find best variable combination</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_supply_model(df):\n",
    "    \"\"\"\n",
    "    Find the best supply function model with lowest p-values and positive log_cprice coefficient.\n",
    "    \"\"\"\n",
    "    # Define the set of variables to try in different combinations (excluding log_wprice, q1, q2, q3)\n",
    "    possible_vars = [ 'log_EthioPrecipitation', 'log_VietPrecipitation' , 'log_ColombPrecipitation',   'log_BrazilPrecipitation']  # Add or remove variables here as needed 'log_bprice',\n",
    "                     \n",
    "    best_model = None\n",
    "    best_pvalue_sum = float('inf')  # Start with an infinitely large p-value sum\n",
    "    best_X_supply = None\n",
    "    best_y_supply = None\n",
    "\n",
    "    # Iterate over all possible combinations of variables (excluding log_cprice, log_wprice, q1, q2, q3)\n",
    "    for r in range(1, len(possible_vars) + 1):\n",
    "        for subset in itertools.combinations(possible_vars, r):\n",
    "            # Include log_cprice, log_wprice, q1, q2, and q3 in all models\n",
    "            selected_vars = ['log_cprice', 'log_wprice', 'q1', 'q2', 'q3'] + list(subset)\n",
    "\n",
    "            # Print each iteration on the same line\n",
    "            print(f\"Trying variables: {selected_vars}\", end=\" | \")\n",
    "\n",
    "            X_supply = df[selected_vars]  # Always include log_cprice, log_wprice, q1, q2, q3\n",
    "            X_supply = sm.add_constant(X_supply)  # Add intercept\n",
    "            y_supply = df['log_qu']\n",
    "\n",
    "            # OLS regression for supply\n",
    "            supply_model = sm.OLS(y_supply, X_supply).fit()\n",
    "\n",
    "            # Check if the p-values of all variables are below a threshold, or in this case find the combination with lowest p-value\n",
    "            pvalues = supply_model.pvalues\n",
    "            pvalue_sum = pvalues.sum() \n",
    "\n",
    "            # Ensure the coefficient of log_cprice is positive\n",
    "            if pvalue_sum < best_pvalue_sum: #supply_model.params['log_cprice'] > 0 and\n",
    "                best_model = supply_model\n",
    "                best_pvalue_sum = pvalue_sum\n",
    "                best_X_supply = X_supply\n",
    "                best_y_supply = y_supply\n",
    "\n",
    "    # Return the best model and the associated data\n",
    "    return best_model, best_X_supply, best_y_supply\n",
    "\n",
    "# Assuming df is your dataframe and it is already prepared with the log variables\n",
    "best_model, best_X_supply, best_y_supply = find_best_supply_model(df)\n",
    "\n",
    "# Print the summary of the best model\n",
    "if best_model is not None:\n",
    "    print(\"\\nBest model found:\")\n",
    "    print(best_model.summary())\n",
    "else:\n",
    "    print(\"\\nNo suitable model found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_demand_model(df):\n",
    "    \"\"\"\n",
    "    Find the best demand function model with lowest p-values and positive log_cprice coefficient.\n",
    "    \"\"\"\n",
    "    # Define the set of variables to try in different combinations (excluding log_wprice, q1, q2, q3)\n",
    "    possible_vars = ['log_tprice', 'log_oprice', 'q4']  # Add or remove variables here as needed 'log_bprice',\n",
    "                     \n",
    "    best_model = None\n",
    "    best_pvalue_sum = float('inf')  # Start with an infinitely large p-value sum\n",
    "    best_X_demand = None\n",
    "    best_y_demand = None\n",
    "\n",
    "    # Iterate over all possible combinations of variables (excluding log_cprice, log_wprice, q1, q2, q3)\n",
    "    for r in range(1, len(possible_vars) + 1):\n",
    "        for subset in itertools.combinations(possible_vars, r):\n",
    "            # Include log_cprice, log_wprice, q1, q2, and q3 in all models\n",
    "            selected_vars = ['log_cprice' , 'log_income', 'q1', 'q2', 'q3'] + list(subset)\n",
    "\n",
    "            # Print each iteration on the same line\n",
    "            print(f\"Trying variables: {selected_vars}\", end=\" | \")\n",
    "\n",
    "            X_demand = df[selected_vars]  # Always include log_cprice, log_wprice, q1, q2, q3\n",
    "            X_demand = sm.add_constant(X_demand)  # Add intercept\n",
    "            y_demand = df['log_qu']\n",
    "\n",
    "            # OLS regression for demand\n",
    "            demand_model = sm.OLS(y_demand, X_demand).fit()\n",
    "\n",
    "            # Check if the p-values of all variables are below a threshold, or in this case find the combination with lowest p-value\n",
    "            pvalues = demand_model.pvalues\n",
    "            pvalue_sum = pvalues.sum() \n",
    "\n",
    "            # Ensure the coefficient of log_cprice is positive\n",
    "            if pvalue_sum < best_pvalue_sum: #demand_model.params['log_cprice'] > 0 and\n",
    "                best_model = demand_model\n",
    "                best_pvalue_sum = pvalue_sum\n",
    "                best_X_demand = X_demand\n",
    "                best_y_demand = y_demand\n",
    "\n",
    "    # Return the best model and the associated data\n",
    "    return best_model, best_X_demand, best_y_demand\n",
    "\n",
    "# Assuming df is your dataframe and it is already prepared with the log variables\n",
    "best_model, best_X_demand, best_y_demand = find_best_demand_model(df)\n",
    "\n",
    "# Print the summary of the best model\n",
    "if best_model is not None:\n",
    "    print(\"\\nBest model found:\")\n",
    "    print(best_model.summary())\n",
    "else:\n",
    "    print(\"\\nNo suitable model found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lasso "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demand\n",
    "lasso_model = Lasso(alpha=0)\n",
    "lasso_model.fit(df[['log_cprice', 'log_income', 'q1', 'q2', 'q3']], df['log_qu'])\n",
    "y_pred = lasso_model.predict(df[['log_cprice', 'log_income', 'q1', 'q2', 'q3']])\n",
    "mse = mean_squared_error(y_pred, df['log_qu'])\n",
    "print('mean_squared_error:',mse)\n",
    "print('Lasso coefficients:',lasso_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supply\n",
    "lasso_model = Lasso(alpha=0)\n",
    "lasso_model.fit(df[['log_cprice', 'log_wprice', 'q1', 'q2', 'q3']], df['log_qu'])\n",
    "y_pred = lasso_model.predict(df[['log_cprice', 'log_wprice', 'q1', 'q2', 'q3']])\n",
    "mse = mean_squared_error(y_pred, df['log_qu'])\n",
    "print('mean_squared_error:',mse)\n",
    "print('Lasso coefficients:',lasso_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supply\n",
    "lasso_model = Lasso(alpha=0)\n",
    "lasso_model.fit(df[['log_cprice', 'log_wprice', 'q1', 'q2', 'q3',\n",
    "                    'log_tprice','log_oprice', 'log_bprice',\n",
    "                    'log_woodpulp', 'log_BrazilPrecipitation',\n",
    "                    'log_BrazilTASMean', 'log_BrazilTASMax', 'log_EthioPrecipitation','log_ColombPrecipitation', 'log_VietPrecipitation'\n",
    "                    ]], df['log_qu'])\n",
    "y_pred = lasso_model.predict(df[['log_cprice', 'log_wprice', 'q1', 'q2', 'q3',\n",
    "                    'log_tprice','log_oprice', 'log_bprice',\n",
    "                    'log_woodpulp', 'log_BrazilPrecipitation',\n",
    "                    'log_BrazilTASMean', 'log_BrazilTASMax', 'log_EthioPrecipitation',\n",
    "                    'log_ColombPrecipitation', 'log_VietPrecipitation'\n",
    "                    ]])\n",
    "mse = mean_squared_error(y_pred, df['log_qu'])\n",
    "print('mean_squared_error:',mse)\n",
    "print('Lasso coefficients:',lasso_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
